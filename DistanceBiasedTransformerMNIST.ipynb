{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b66f4bb-7ebf-4918-b584-4921e929eaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "\n",
    "# 0. DIRECTORY SETUP\n",
    "BASE_DIR = r\"D:\\Anaconda\\Projects\\TransformerArchitecture\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "MODEL_SAVE_PATH = os.path.join(BASE_DIR, \"trained_mnist_transformer.pth\")\n",
    "\n",
    "# Ensure your custom directories exist\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Setup device to use the GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a7aa571-7995-44ee-8338-b9f0d1f5f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. THE ARCHITECTURE\n",
    "class DistanceBiasedAttention(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.Q = nn.Linear(d_model, d_model)\n",
    "        self.K = nn.Linear(d_model, d_model)\n",
    "        self.V = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.distance_weight = nn.Parameter(torch.tensor(0.1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, seq_len, _ = x.shape\n",
    "        \n",
    "        q = self.Q(x)\n",
    "        k = self.K(x)\n",
    "        v = self.V(x)\n",
    "        \n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.d_model ** 0.5)\n",
    "        \n",
    "        indices = torch.arange(seq_len, device=x.device)\n",
    "        distance_matrix = torch.abs(indices.unsqueeze(0) - indices.unsqueeze(1))\n",
    "        \n",
    "        scores = scores - (distance_matrix * self.distance_weight)\n",
    "        \n",
    "        attn_weights = torch.softmax(scores, dim=-1)\n",
    "        output = torch.matmul(attn_weights, v)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class MNISTTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(1, 64) \n",
    "        \n",
    "        self.attn1 = DistanceBiasedAttention(d_model=64)\n",
    "        self.norm1a = nn.LayerNorm(64)\n",
    "        self.ffn1 = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64)\n",
    "        )\n",
    "        self.norm1b = nn.LayerNorm(64)\n",
    "        \n",
    "        self.attn2 = DistanceBiasedAttention(d_model=64)\n",
    "        self.norm2a = nn.LayerNorm(64)\n",
    "        self.ffn2 = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64)\n",
    "        )\n",
    "        self.norm2b = nn.LayerNorm(64)\n",
    "        \n",
    "        self.classifier = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        x = x.view(b, h*w, 1) \n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        attn_out = self.attn1(x)\n",
    "        x = self.norm1a(x + attn_out)\n",
    "        ffn_out = self.ffn1(x)\n",
    "        x = self.norm1b(x + ffn_out)\n",
    "\n",
    "        attn_out = self.attn2(x)\n",
    "        x = self.norm2a(x + attn_out)\n",
    "        ffn_out = self.ffn2(x)\n",
    "        x = self.norm2b(x + ffn_out)\n",
    "        \n",
    "        x = x.mean(dim=1) \n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da3d8e83-ce6f-4322-9857-3be16e3e4f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading/Loading MNIST Data to D:\\Anaconda\\Projects\\TransformerArchitecture\\data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training on cuda...\n",
      "----------------------------------------\n",
      "   Epoch 1 | Batch 000/469 | Loss: 2.2810\n",
      "   Epoch 1 | Batch 150/469 | Loss: 1.8813\n",
      "   Epoch 1 | Batch 300/469 | Loss: 1.6000\n",
      "   Epoch 1 | Batch 450/469 | Loss: 1.4979\n",
      "----------------------------------------\n",
      " Epoch 1 Summary:\n",
      "   Time     : 148.9s\n",
      "   Train Acc: 34.73% | Test Acc: 46.52%\n",
      "----------------------------------------\n",
      "\n",
      "   Epoch 2 | Batch 000/469 | Loss: 1.4785\n",
      "   Epoch 2 | Batch 150/469 | Loss: 1.4166\n",
      "   Epoch 2 | Batch 300/469 | Loss: 1.2491\n",
      "   Epoch 2 | Batch 450/469 | Loss: 1.1843\n",
      "----------------------------------------\n",
      " Epoch 2 Summary:\n",
      "   Time     : 143.5s\n",
      "   Train Acc: 55.89% | Test Acc: 62.47%\n",
      "----------------------------------------\n",
      "\n",
      "   Epoch 3 | Batch 000/469 | Loss: 1.0743\n",
      "   Epoch 3 | Batch 150/469 | Loss: 0.9476\n",
      "   Epoch 3 | Batch 300/469 | Loss: 0.9811\n",
      "   Epoch 3 | Batch 450/469 | Loss: 0.8998\n",
      "----------------------------------------\n",
      " Epoch 3 Summary:\n",
      "   Time     : 143.0s\n",
      "   Train Acc: 65.19% | Test Acc: 63.07%\n",
      "----------------------------------------\n",
      "\n",
      "   Epoch 4 | Batch 000/469 | Loss: 1.0740\n",
      "   Epoch 4 | Batch 150/469 | Loss: 0.9225\n",
      "   Epoch 4 | Batch 300/469 | Loss: 0.7962\n",
      "   Epoch 4 | Batch 450/469 | Loss: 0.9174\n",
      "----------------------------------------\n",
      " Epoch 4 Summary:\n",
      "   Time     : 144.0s\n",
      "   Train Acc: 69.94% | Test Acc: 66.62%\n",
      "----------------------------------------\n",
      "\n",
      "   Epoch 5 | Batch 000/469 | Loss: 0.8249\n",
      "   Epoch 5 | Batch 150/469 | Loss: 0.6713\n",
      "   Epoch 5 | Batch 300/469 | Loss: 0.9724\n",
      "   Epoch 5 | Batch 450/469 | Loss: 0.8183\n",
      "----------------------------------------\n",
      " Epoch 5 Summary:\n",
      "   Time     : 143.2s\n",
      "   Train Acc: 73.46% | Test Acc: 75.05%\n",
      "----------------------------------------\n",
      "\n",
      "   Epoch 6 | Batch 000/469 | Loss: 0.9354\n",
      "   Epoch 6 | Batch 150/469 | Loss: 0.8264\n",
      "   Epoch 6 | Batch 300/469 | Loss: 0.7118\n",
      "   Epoch 6 | Batch 450/469 | Loss: 0.9308\n",
      "----------------------------------------\n",
      " Epoch 6 Summary:\n",
      "   Time     : 146.7s\n",
      "   Train Acc: 75.56% | Test Acc: 78.60%\n",
      "----------------------------------------\n",
      "\n",
      "   Epoch 7 | Batch 000/469 | Loss: 0.6742\n",
      "   Epoch 7 | Batch 150/469 | Loss: 0.5992\n",
      "   Epoch 7 | Batch 300/469 | Loss: 0.6805\n",
      "   Epoch 7 | Batch 450/469 | Loss: 0.7149\n",
      "----------------------------------------\n",
      " Epoch 7 Summary:\n",
      "   Time     : 142.8s\n",
      "   Train Acc: 77.15% | Test Acc: 78.72%\n",
      "----------------------------------------\n",
      "\n",
      "   Epoch 8 | Batch 000/469 | Loss: 0.5707\n",
      "   Epoch 8 | Batch 150/469 | Loss: 0.5375\n",
      "   Epoch 8 | Batch 300/469 | Loss: 0.6367\n",
      "   Epoch 8 | Batch 450/469 | Loss: 0.7593\n",
      "----------------------------------------\n",
      " Epoch 8 Summary:\n",
      "   Time     : 142.8s\n",
      "   Train Acc: 77.88% | Test Acc: 78.06%\n",
      "----------------------------------------\n",
      "\n",
      "   Epoch 9 | Batch 000/469 | Loss: 0.6683\n",
      "   Epoch 9 | Batch 150/469 | Loss: 0.6059\n",
      "   Epoch 9 | Batch 300/469 | Loss: 0.5804\n",
      "   Epoch 9 | Batch 450/469 | Loss: 0.5173\n",
      "----------------------------------------\n",
      " Epoch 9 Summary:\n",
      "   Time     : 144.7s\n",
      "   Train Acc: 78.45% | Test Acc: 80.48%\n",
      "----------------------------------------\n",
      "\n",
      "   Epoch 10 | Batch 000/469 | Loss: 0.5884\n",
      "   Epoch 10 | Batch 150/469 | Loss: 0.7060\n",
      "   Epoch 10 | Batch 300/469 | Loss: 0.7342\n",
      "   Epoch 10 | Batch 450/469 | Loss: 0.5123\n",
      "----------------------------------------\n",
      " Epoch 10 Summary:\n",
      "   Time     : 144.3s\n",
      "   Train Acc: 79.28% | Test Acc: 81.22%\n",
      "----------------------------------------\n",
      "\n",
      "Model weights successfully saved to: D:\\Anaconda\\Projects\\TransformerArchitecture\\trained_mnist_transformer.pth\n"
     ]
    }
   ],
   "source": [
    "# 2. DATA LOADING & TRAINING\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10 \n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "print(f\"\\nDownloading/Loading MNIST Data to {DATA_DIR}...\")\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=DATA_DIR, train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=DATA_DIR, train=False, download=True, transform=transform)\n",
    "\n",
    "# pin_memory=True keeps RAM-to-VRAM transfers fast\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
    "\n",
    "model = MNISTTransformer().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"\\nStarting Training on {device}...\\n\" + \"-\"*40)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        \n",
    "        if batch_idx % 150 == 0:\n",
    "            print(f\"   Epoch {epoch+1} | Batch {batch_idx:03d}/{len(train_loader)} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    test_correct, test_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            test_total += target.size(0)\n",
    "            test_correct += (predicted == target).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    test_acc = 100 * test_correct / test_total\n",
    "    epoch_time = time.time() - start_time\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\" Epoch {epoch+1} Summary:\")\n",
    "    print(f\"   Time     : {epoch_time:.1f}s\")\n",
    "    print(f\"   Train Acc: {train_acc:.2f}% | Test Acc: {test_acc:.2f}%\")\n",
    "    print(\"-\" * 40 + \"\\n\")\n",
    "\n",
    "# SAVE THE TRAINED WEIGHTS\n",
    "torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "print(f\"Model weights successfully saved to: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "805888a8-8489-45c5-b778-4c2e3af4fec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TESTING THE SAVED MODEL ---\n",
      "Successfully loaded trained weights from D:\\Anaconda\\Projects\\TransformerArchitecture\\trained_mnist_transformer.pth!\n",
      "Image Index: #7024\n",
      " The AI guessed: 3\n",
      " The actual answer was: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. TESTING THE SAVED MODEL\n",
    "print(\"\\n--- TESTING THE SAVED MODEL ---\")\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "test_dataset = datasets.MNIST(root=DATA_DIR, train=False, download=False, transform=transform) \n",
    "\n",
    "# Initialize the architecture\n",
    "model = MNISTTransformer().to(device)\n",
    "\n",
    "# Load the weights from your Anaconda projects folder\n",
    "try:\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "    print(f\"Successfully loaded trained weights from {MODEL_SAVE_PATH}!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find model weights at {MODEL_SAVE_PATH}. Did you run the training cell?\")\n",
    "    \n",
    "model.eval()\n",
    "\n",
    "# Pick a random image\n",
    "random_index = random.randint(0, len(test_dataset) - 1)\n",
    "single_image, true_label = test_dataset[random_index]\n",
    "\n",
    "# THE FIX: Just add a batch dimension so the shape is [1, 1, 28, 28]\n",
    "# and move it to your GTX 1650\n",
    "batched_image = single_image.unsqueeze(0).to(device)\n",
    "\n",
    "# Get prediction\n",
    "with torch.no_grad():\n",
    "    output = model(batched_image)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    predicted_label = predicted.item()\n",
    "    \n",
    "print(f\"Image Index: #{random_index}\")\n",
    "print(f\" The AI guessed: {predicted_label}\")\n",
    "print(f\" The actual answer was: {true_label}\")\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(single_image.squeeze().cpu(), cmap='gray')\n",
    "\n",
    "color = 'green' if predicted_label == true_label else 'red'\n",
    "plt.title(f\"AI Guessed: {predicted_label} | Actual: {true_label}\", color=color)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3755e28d-78f0-4250-8846-781e711e4676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TESTING THE SAVED MODEL ---\n",
      "Successfully loaded trained weights from D:\\Anaconda\\Projects\\TransformerArchitecture\\trained_mnist_transformer.pth!\n",
      "Image Index: #8688\n",
      " The AI guessed: 7\n",
      " The actual answer was: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. TESTING THE SAVED MODEL\n",
    "print(\"\\n--- TESTING THE SAVED MODEL ---\")\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "test_dataset = datasets.MNIST(root=DATA_DIR, train=False, download=False, transform=transform) \n",
    "\n",
    "# Initialize the architecture\n",
    "model = MNISTTransformer().to(device)\n",
    "\n",
    "# Load the weights from your Anaconda projects folder\n",
    "try:\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "    print(f\"Successfully loaded trained weights from {MODEL_SAVE_PATH}!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find model weights at {MODEL_SAVE_PATH}. Did you run the training cell?\")\n",
    "    \n",
    "model.eval()\n",
    "\n",
    "# Pick a random image\n",
    "random_index = random.randint(0, len(test_dataset) - 1)\n",
    "single_image, true_label = test_dataset[random_index]\n",
    "\n",
    "# THE FIX: Just add a batch dimension so the shape is [1, 1, 28, 28]\n",
    "# and move it to your GTX 1650\n",
    "batched_image = single_image.unsqueeze(0).to(device)\n",
    "\n",
    "# Get prediction\n",
    "with torch.no_grad():\n",
    "    output = model(batched_image)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    predicted_label = predicted.item()\n",
    "    \n",
    "print(f\"Image Index: #{random_index}\")\n",
    "print(f\" The AI guessed: {predicted_label}\")\n",
    "print(f\" The actual answer was: {true_label}\")\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(single_image.squeeze().cpu(), cmap='gray')\n",
    "\n",
    "color = 'green' if predicted_label == true_label else 'red'\n",
    "plt.title(f\"AI Guessed: {predicted_label} | Actual: {true_label}\", color=color)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fada663d-7c59-4142-8626-05b292a044f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TESTING THE SAVED MODEL ---\n",
      "Successfully loaded trained weights from D:\\Anaconda\\Projects\\TransformerArchitecture\\trained_mnist_transformer.pth!\n",
      "Image Index: #2625\n",
      " The AI guessed: 2\n",
      " The actual answer was: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. TESTING THE SAVED MODEL\n",
    "print(\"\\n--- TESTING THE SAVED MODEL ---\")\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "test_dataset = datasets.MNIST(root=DATA_DIR, train=False, download=False, transform=transform) \n",
    "\n",
    "# Initialize the architecture\n",
    "model = MNISTTransformer().to(device)\n",
    "\n",
    "# Load the weights from your Anaconda projects folder\n",
    "try:\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "    print(f\"Successfully loaded trained weights from {MODEL_SAVE_PATH}!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find model weights at {MODEL_SAVE_PATH}. Did you run the training cell?\")\n",
    "    \n",
    "model.eval()\n",
    "\n",
    "# Pick a random image\n",
    "random_index = random.randint(0, len(test_dataset) - 1)\n",
    "single_image, true_label = test_dataset[random_index]\n",
    "\n",
    "# THE FIX: Just add a batch dimension so the shape is [1, 1, 28, 28]\n",
    "# and move it to your GTX 1650\n",
    "batched_image = single_image.unsqueeze(0).to(device)\n",
    "\n",
    "# Get prediction\n",
    "with torch.no_grad():\n",
    "    output = model(batched_image)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    predicted_label = predicted.item()\n",
    "    \n",
    "print(f\"Image Index: #{random_index}\")\n",
    "print(f\" The AI guessed: {predicted_label}\")\n",
    "print(f\" The actual answer was: {true_label}\")\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(single_image.squeeze().cpu(), cmap='gray')\n",
    "\n",
    "color = 'green' if predicted_label == true_label else 'red'\n",
    "plt.title(f\"AI Guessed: {predicted_label} | Actual: {true_label}\", color=color)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482e5786-3eb8-4c3e-978b-73a7f413f622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow GPU (D Drive)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
